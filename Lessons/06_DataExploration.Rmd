---
title: "6: Data Exploration"
author: "Environmental Data Analytics | Kateri Salk"
date: "Spring 2019"
output: pdf_document
geometry: margin=2.54cm
fig_width: 5
fig_height: 2.5
editor_options: 
  chunk_output_type: console
---

## LESSON OBJECTIVES
1. Set up a data analysis session in RStudio
2. Import and explore datasets in R
3. Apply data exploration skills to a real-world example dataset

## OPENING DISCUSSION: WHY DO WE EXPLORE OUR DATA?

Why is data exploration our first step in analyzing a dataset? What information do we gain? How does data exploration aid in our decision-making for data analysis steps further down the pipeline?

## IMPORT DATA AND VIEW SUMMARIES

```{r}
# 1. Set up your working directory
getwd()

# 2. Load packges
library(tidyverse)

# 3. Import datasets
USGS.flow.data <- read.csv("./Data/Raw/USGS_Site02085000_Flow_Raw.csv")

View(USGS.flow.data)
# Alternate option: click on data frame in Environment tab

class(USGS.flow.data)
colnames(USGS.flow.data)

# Rename columns
colnames(USGS.flow.data) <- c("agency_cd", "site_no", "datetime", 
                              "discharge.max", "discharge.max.approval", 
                              "discharge.min", "discharge.min.approval", 
                              "discharge.mean", "discharge.mean.approval", 
                              "gage.height.max", "gage.height.max.approval", 
                              "gage.height.min", "gage.height.min.approval", 
                              "gage.height.mean", "gage.height.mean.approval")
str(USGS.flow.data)
dim(USGS.flow.data)

#head(USGS.flow.data)
class(USGS.flow.data$datetime)

```

## ADJUSTING DATASETS

### Formatting dates

R will often import dates as factors or characters rather than dates. To fix, this we need to tell R that it is looking at dates. We also need to specify the format the dates are in. By default, if you don't provide a format, R will attempt to use %Y-%m-%d or %Y/%m/%d as a default. Note: if you are working collaboratively in an international setting, using a year-month-day format in spreadsheets is the least ambiguous of date formats. Make sure to check whether month-day-year or day-month-year is used in an ambiguously formatted spreadsheet.

Formatting of dates in R: 

%d  day as number (0-31)
%m  month (00-12, can be e.g., 01 or 1)
%y  2-digit year
%Y  4-digit year
%a  abbreviated weekday
%A  unabbreviated weekday
%b  abbreviated month
%B  unabbreviated month

In some cases when dates are provided as integers, you may need to provide an origin for your dates. Beware: the "origin" date for Excel (Windows), Excel (Mac), R, and MATLAB all have different origin dates. Google this if it comes up.

```{r}
help(as.Date)

# Adjust date formatting for today
# Write code for three different date formats. 
# An example is provided to get you started.
# (code must be uncommented)
today <- Sys.Date()
format(today, format = "%B %d, %Y")
format(today, format = "%a")
format(today, format = "%y")
format(today, format = "%b")

USGS.flow.data$datetime <- as.Date(USGS.flow.data$datetime, format = "%m/%d/%y") 
```

Note that for every date prior to 1969, R has assigned the date in the 2000s rather than the 1900s. This can be fixed with an `ifelse` statement inside a function. Run through the code below and write what is happening in the comment above each line.

```{r}
# Formated date column to be year, month, day
USGS.flow.data$datetime <- format(USGS.flow.data$datetime, "%y%m%d")

# Created function, saying if the date is greater than 12/31/2018, then give 19 for the first 2 values of the year, if not, give 20 for the first 2 values of the year
create.early.dates <- (function(d) {
       paste0(ifelse(d > 181231,"19","20"),d)
       })
# Makes year 4 digits instead of 2
USGS.flow.data$datetime <- create.early.dates(USGS.flow.data$datetime)

# Sets elements as date and not numeric
USGS.flow.data$datetime <- as.Date(USGS.flow.data$datetime, format = "%Y%m%d") 

```

### Removing NAs

Notice in our dataset that our discharge and gage height observations have many NAs, meaning no measurement was recorded for a specific day. In some cases, it might be in our best interest to remove NAs from a dataset. Removing NAs or not will depend on your research question.

```{r}
summary(USGS.flow.data$discharge.mean)
summary(USGS.flow.data$gage.height.mean)
```
Question: What types of research questions might make it favorable to remove NAs from a dataset, and what types of research questions might make it favorable to retain NAs in the dataset?

> Answer: May want to remove if you want to quantitatively analyze data, especially because R may fill in blank cells with NA. May want to retain them if that's an answer to a question in a survey, for example. May want to remove NAs because statistical models, like time series, can't function with NAs

```{r}
# created a dataset that omits the NA rows, which is why the complete dataset has some many less rows
USGS.flow.data.complete <- na.omit(USGS.flow.data)
dim(USGS.flow.data)
dim(USGS.flow.data.complete)

# complete.cases function will tell you which rows have complete data (no NAs in the row)

mean(USGS.flow.data.complete$discharge.mean)
sd(USGS.flow.data.complete$discharge.mean)
summary(USGS.flow.data.complete$discharge.mean)

```

## VISUALIZATION FOR DATA EXPLORATION

Although the `summary()` function is helpful in getting an idea of the spread of values in a numeric dataset, it can be useful to create visual representations of the data to help form hypotheses and direct downstream data analysis. Below is a summary of the useful types of graphs that can be 

Note: each of these approaches utilize the package "ggplot2". We will be covering the syntax of ggplot in a later lesson, but for now you should familiarize yourself with the functionality of what each command is doing.

### Bar Chart (function: geom_bar)

Visualize count data for categorical variables. 

```{r, fig.height = 3, fig.width = 4}
ggplot(USGS.flow.data.complete, aes(x = discharge.mean.approval)) +
  geom_bar()

#aes are the asthetics, so what we want our x axis to be (in this case it's whether or not the data has been approved). geom_bar is indicating that we want a bar chart (it's good for categorical variables, like approved vs. pending)
```

### Histogram (function: geom_histogram)

Visualize distributions of values for continuous numerical variables. What is happening in each line of code? Insert a comment above each line.

```{r, fig.height = 3, fig.width = 4}
# Mean discharge plotted on x axis as a histogram
ggplot(USGS.flow.data.complete) +
  geom_histogram(aes(x = discharge.mean))

# Same as above, but with more narrow bin width, which is 10 units wide (in this case discharge)
ggplot(USGS.flow.data.complete) +
  geom_histogram(aes(x = discharge.mean), binwidth = 10)

# Specifies the number of bins we want
ggplot(USGS.flow.data.complete) +
  geom_histogram(aes(x = discharge.mean), bins = 20)

# Reduces x axis to 500 (from 3000, which was the default here) 
ggplot(USGS.flow.data.complete, aes(x = discharge.mean)) +
  geom_histogram(binwidth = 10) + 
  scale_x_continuous(limits = c(0, 500))
  
#
ggplot(USGS.flow.data.complete) +
  geom_histogram(aes(x = gage.height.mean))

```
### Frequency line graph (function: geom_freqpoly)

An alternate to a histogram is a frequency polygon graph (distributions of values for continuous numerical variables). Instead of displaying bars,  counts of continuous variables are displayed as lines. This is advantageous if you want to display multiple variables or categories of variables at once.

```{r, fig.height = 3, fig.width = 4}
# This is creating 3 curves from 3 different columns 
ggplot(USGS.flow.data.complete) +
  geom_freqpoly(aes(x = gage.height.mean), bins = 50) +
  geom_freqpoly(aes(x = gage.height.min), bins = 50, color = "blue") +
  geom_freqpoly(aes(x = gage.height.max), bins = 50, color = "red") +
  scale_x_continuous(limits = c(0, 10))

# Plots 1 column, but splits it based on categorical column (approval).
# color = here indicates that you want to color the lines based on the approval column
ggplot(USGS.flow.data.complete) +
  geom_freqpoly(aes(x = gage.height.mean, color = gage.height.mean.approval), bins = 50) +
  scale_x_continuous(limits = c(0, 10)) +
  theme(legend.position = "top")

```
### Box-and-whisker plots (function: geom_boxplot)

A box-and-whisker plot is yet another alternative to histograms (distributions of values for continuous numerical variables). These plots consist of: 

* A box from the 25th to the 75th percentile of the data, called the interquartile range (IQR).

* A bold line inside the box representing the median value of the data. Whether the median is in the center or off to one side of the IQR will give you an idea about the skewness of your data.

* A line outside of the box representing values falling within 1.5 times the IQR. 

* Points representing outliers, values that fall outside 1.5 times the IQR. 

An alternate option is a violin plot, which displays density distributions, somewhat like a hybrid of the box-and-whiskers and the frequency polygon plot.

```{r, fig.height = 3, fig.width = 4}
# Plot values of mean, and split it up based on approval
ggplot(USGS.flow.data.complete) +
  geom_boxplot(aes(x = gage.height.mean.approval, y = gage.height.mean))

# Divides box-whisker plot among gage height, by 1 unit
# Useful when relationship between variables that don't have linear relationship
ggplot(USGS.flow.data.complete) +
  geom_boxplot(aes(x = gage.height.mean, y = discharge.mean, group = cut_width(gage.height.mean, 1)))

# 
ggplot(USGS.flow.data.complete) +
  geom_violin(aes(x = gage.height.mean.approval, y = gage.height.mean), draw_quantiles = c(0.25, 0.5, 0.75))
```

Question: what are the pros and cons of each type of frequency graph (histogram, frequency polygon, box-and whisker, violin)?

> Answer: 


### Scatterplot (function: geom_point)
Visualize relationships between continuous numerical variables.

```{r, fig.height = 3, fig.width = 4}
# Code above only applies to when you knit the graph. It's set like this to better fit on a PDF

ggplot(USGS.flow.data.complete) +
  geom_point(aes(x = discharge.mean, y = gage.height.mean))

```

## ENDING DISCUSSION

How can multiple options for data exploration inform our understanding of our data? What did you learn about the USGS discharge dataset today?

> ANSWER: 

This passage from R for Data Science sums up some of the questions we should ask ourselves when initially exploring a dataset. "Patterns in your data provide clues about relationships. If a systematic relationship exists between two variables it will appear as a pattern in the data. If you spot a pattern, ask yourself:

"Could this pattern be due to coincidence (i.e. random chance)?

"How can you describe the relationship implied by the pattern?

"How strong is the relationship implied by the pattern?

"What other variables might affect the relationship?

"Does the relationship change if you look at individual subgroups of the data?"

Do you see any patterns in the USGS data for the Eno River? What might be responsible for those patterns and/or relationships?

> ANSWER: 


```{r}

```
